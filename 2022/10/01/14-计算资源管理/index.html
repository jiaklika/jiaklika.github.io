<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">




  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">





















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.1">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=7.0.1">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.1">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.1" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.0.1',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="思考并回答以下问题：  总结一下，这章作者最主要想表达什么观点？">
<meta name="keywords" content="Kubernetes in Action">
<meta property="og:type" content="article">
<meta property="og:title" content="14-计算资源管理">
<meta property="og:url" content="http://yoursite.com/2022/10/01/14-计算资源管理/index.html">
<meta property="og:site_name" content="车斌的技术博客">
<meta property="og:description" content="思考并回答以下问题：  总结一下，这章作者最主要想表达什么观点？">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2022-10-04T02:34:28.244Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="14-计算资源管理">
<meta name="twitter:description" content="思考并回答以下问题：  总结一下，这章作者最主要想表达什么观点？">






  <link rel="canonical" href="http://yoursite.com/2022/10/01/14-计算资源管理/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>14-计算资源管理 | 车斌的技术博客</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">车斌的技术博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">放弃会成为一种习惯</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/10/01/14-计算资源管理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CheBin">
      <meta itemprop="description" content="看书不是为了学习，是为了锻炼意志力">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="车斌的技术博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">14-计算资源管理

              
            
          </h1>
        

        <div class="post-meta">

          

          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2022-10-01 10:11:25" itemprop="dateCreated datePublished" datetime="2022-10-01T10:11:25+08:00">2022-10-01</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2022-10-04 10:34:28" itemprop="dateModified" datetime="2022-10-04T10:34:28+08:00">2022-10-04</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">24k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">22 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>思考并回答以下问题：</p>
<ul>
<li>总结一下，这章作者最主要想表达什么观点？</li>
</ul>
<a id="more"></a>
<p>本章内容涵盖<br>■为容器申请CPU、内存以及其他计算资源<br>配置CPU、内存的硬限制<br>■理解pod的QoS机制<br>■为命名空间中每个pod配置默认、最大、最<br>小资源限制<br>■为命名空间配置可用资源总数<br>到目前为止，我们在创建pod时并不关心它们使用CPU和内存资源的最大值。不过在本章你会了解到，为一个pod配置资源的预期使用量和最大使用量是pod定义中的重要组成部分。通过设置这两组参数，可以确保pod公平地使用Kubemetes集群资源，同时也影响着整个集群pod的调度方式。<br>14.1 为pod中的容器申请资源<br>我们创建一个pod时，可以指定容器对CPU和内存的资源请求量（即requests），以及资源限制量（即limits）。它们并不在pod里定义，而是针对每个容</p>
<p>器单独指定。pod 对资源的请求量和限制量是它所包含的所有容器的请求量和限制量之和。<br>14.1.1 创建包含资源 requests 的 pod<br>让我们看一个示例 pod 的定义， 它只有一个容器，我们为其指定了 CPU 和内存的资源请求量，如下代码清单所示。<br>代码清单14.1定义了资源 requests 的 pod： requests-pod.yam| </p>
<p>在pod manifest中，我们声明了一个容器需要1/5核（200毫核）的CPU才能正常运行。换句话说，五个同样的pod（或容器）可以足够快地运行在一个CPU核上。<br>当我们不指定CPU requests时，表示我们并不关心系统为容器内的进程分配了多少CPU时间。在最坏情况下进程可能根本分不到CPU时间（当其他进程对CPU需求量很大时会发生）。这对一些时间不敏感、低优先级的batch jobs没有问题，但对于处理用户请求的容器这样配置显然不太合适。<br>在podspec里，我们同时为容器申请了10MB的内存，说明我们期望容器内的进程最大消耗10MB的RAM。它们可能实际占用较小，但在正常情况下我们并不希望它们占用超过这个值。在本章后面我们将看到如果超过会发生什么。<br>现在运行pod。当pod启动时，可以通过在容器中运行top命令快速查看进程的CPU使用，如下面的代码清单所示。</p>
<p>我们在容器内执行dd命令会消耗尽可能多的CPU，但因为它是单线程运行所以最多只能跑满一个核，而MinikubeVM拥有两个核，这就是为什么top命令显示进程只占用了50%CPU的原因。<br>对于两核来说，50%显然就是指一个核，说明容器实际使用量超过了我们在pod定义中申请的200毫核。这是符合预期的，因为requests不会限制容器可以使用的CPU数量。我们需要指定CPU限制实现这一点，稍后会进行尝试，不过首先我们看看在pod中指定资源requests对pod调度的影响。<br>14.1.2资源requests如何影响调度<br>通过设置资源requests我们指定了pod对资源需求的最小值。调度器在将pod调度到节点的过程中会用到该信息。每个节点可分配给pod的CPU和内存数量都是一定的。调度器在调度时只考虑那些未分配资源量满足pod需求量的节点。如果节点的未分配资源量小于pod需求量，这时节点没有能力提供pod对资源需求的最小量，因此Kubemetes不会将该pod调度到这个节点。<br>调度器如何判断一个pod是否适合调度到某个节点<br>这里比较重要而且会令人觉得意外的是，调度器在调度时并不关注各类资源在当前时刻的实际使用量，而只关心节点上部署的所有pod的资源申请量之和。尽管现有pods的资源实际使用量可能小于它的申请量，但如果使用基于实际资源消耗量的调度算法将打破系统为这些已部署成功的pods提供足够资源的保证。<br>从图14.1中可见，节点上部署了三个pod。它们共申请了节点80%的CPU和60%的内存资源。图右下方的podD将无法调度到这个节点上，因为它25%的CPU requests大于节点未分配的20%CPU。而实际上，这与当前三个pods仅使用70%的CPU没有什么关系。</p>
<p>图14.1调度器只关注资源 requests， 并不关注实际使用量<br>调度器如何利用 pod requests 为其选择最佳节点<br>你也许还记得，在第 11 章中调度器首先会对节点列表进行过滤， 排除那些不满足需求的节点，然后根据预先配置的优先级函数对其余节点进行排序。 其中有两个基于资源请求量的优先级排序函数： LeastRequestedPriority和 MostRequestedPriority。前者优先将 pod 调度到请求量少的节点上（也就是 拥有更多未分配资源的节点），而后者相反， 优先调度到请求量多的节点（拥有更少 未分配资源的节点）。但是， 正如我们刚刚解释的， 它们都只考虑资源请求量，而不关注实际使用资源量。<br>调度 器 只 能配置一种优先级函数。 你可能在想为什么有人会使用 MostRequestedPriority 函数。 毕竟如果你有一组节点， 通常会使其负载平均分布，但是在随时可以增加或删除节点的云基础设施上运行时并非如此。 配置调度器使用 MostRequestedPriority 函数， 可以在为每个 pod 提供足量 CPU / 内 存资源的同时， 确保 Kubernetes 使用尽可能少的节点。 通过使 pod 紧凑地编排，一些节点可以保持空闲并可随时从集群中移除。 由于通常会按照单个节点付费，这样便可以节省一笔开销。<br>查看节点资源总量<br>我们来看看调度器的行为。 我们将部署另一个资源请求量是之前4倍的 pod。但在这之前， 我们先看看什么是节点资源总量。 因为调度器需要知道每个节点拥有多少 CPU和 内存资源，Kubelet 会向 API 服务器报告相关数据，并通过节点资源对 外提供访问，可以使用 kubectl describe 命令进行查看， 如以下代码清单所示。</p>
<p>命令的输出展示了节点可用资源相关的两组数量：节点资源总量和可分配资源量。资源总量代表节点所有的资源总和，包括那些可能对pod不可用的资源。有些资源会为Kubemetes或者系统组件预留。调度器的决策仅仅基于可分配资源量。<br>单节点的minikube集群运行于2核的VM之上，同时从.上面的例子中可以看到节点没有预留资源，全部CPU都可以分配给pod。因此，调度器再调度另一个申请了800毫核的pod是没有问题的。<br>让我们运行这个pod。可以使用示例代码中的YAML文件，或者简单地执行以下命令：<br>; kubectl run requests-pod-2 — image=busybox — restart Never</p>
<ul>
<li>—requests= “ cpu=800m, memory=20Mi’ — dd if=/dev/zero of=/dev/null<br>pod “requests-pod-2” created<br>我们来看看它是否被成功调度：<br>$ kubect1 get po requests-pod-2<br>READY STATUS RESTARTS AGE<br>reaue<br>Runnina<br>requests-pod-2 /1<br>KunniT<br>没问题，这个pod已经被成功调度而且开始运行了。<br>创建一个不适合任何节点的pod<br>我们现在部署了两个pod，共申请了1000 毫核CPU。所以我们应该还剩下1核可供其他pod使用，是吧？因此我们再部署- 一个资源申请量为1核的pod。使用与前面类似的命令：<br>$ kubectl run requests-pod-3 — image=busybox —restart Never<br>ceguests=icpu=1 , memory=20Mi: . ad ifidauinero。<br>if=/dev/zero of= /dev/null<br>requests=’ cpu=l, memory=20Mi’<br>pod “requests-pod-2” created<br>注意这次我们指定CPU请求量为1核（cpu=1）而不是1000毫核( cpu=1000m )。</li>
</ul>
<p>到目前为止一切顺利，pod被API服务器接收（你一定记得前面章节提到当pod不合法时API服务器会拒绝该pod的创建请求）<br>$ kubectl get po requests-pod-3 NAME<br>READY<br>STATUS<br>RESTARTS 0<br>AGE<br>requests-pod-3<br>0/1<br>Pending<br>4m<br>尽管我们等了好一会，pod依然卡在Pending状态，可以通过describe命令查看一下出现这种情况的详细原因，如以下代码清单所示。<br>代码清单14.4使用kubectl describe pod查看为什么pod卡在Pending状态</p>
<p>从命令的输出可以看出我们的单节点集群没有足够的CPU，pod不适合任何节点因此没有被成功调度。但是为什么呢？我们三个pod的CPUrequests总和是2000毫核也就是2核，我们的节点正好可以提供，是哪里出了问题呢？<br>查明pod没有被调度成功的原因<br>可以通过检查节点资源找出为什么pod没有成功调度。让我们再次执行 kubectl describe node 命令并仔细地检查输出。<br>代码清单14.5使用kubectl describenode检查节点已分配资源</p>
<p>在列表的左下角可以看到共有 1275 毫核已经被运行的 pod 申请， 比我们先前部署的两个 pod 申请量多了275毫核。 看来有些东西吃掉了额外的 CPU 资源。<br>我们可以在上面的列表中找到罪魁祸首。 在 kube-system命名空间内有三个 pod 明确申请了 CPU。 这些 pod 加上我们的两个 pod，只剩下 725 毫核可用。第三个 pod 需要 1000毫核， 调度器不会将其调度到这个节点上， 因为这将导致节点超卖。释放资源让 pod 正常调度<br>只有当节点资源释放后（比如删除之前两个 pod 中的一个） pod 才会调度上来。 如果我们删除第二个 pod， 周度器将获取到删除通知（通过第11 章介绍的监控机制），并在第二个 pod 成功终止后立即调度第三个 pod。 这在下面的代码清单中可以看到。<br>代码清单 14.6删除另一个 pod 后看到 pod 已正常调度</p>
<p>在以上所有例子中，我们也指定了内存申请量，不过它并没有对调度产生影响，因为我们的节点拥有足够多的内存来容纳所有pod的需求。调度器处理CPU和内存requests的方式没有什么不同，但与内存requests相反的是，pod的CPU requests在其运行时也扮演着一个角色，我们将在下文中了解这一点。</p>
<p>14.1.3 CPU requests 如何影响 CPU 时间分配<br>现在有两个 pod 运行在集群中 （我们暂且不理会那些系统pod， 因为它们大部分时间都是空闲的）。一个请求了200毫核， 另一个是前者的 5 倍。在本章开始，我 们说到 Kubernetes 会将 requests 资源和 limits 资源区别对待。我们还没有定义任何  limits，因此每个 pod 分別可以消耗多少 CPU 并没有做任何限制。那么假设每个 pod  内的进程都尽情消耗 CPU 时间，每个 pod 最终能分到多少 CPU 时间呢？<br>CPU requests 不仅仅在调度时起作用， 它还决定着剩余（未使用）的 CPU时间 如何在 pod 之间分配。正如图 14.2 描绘的那样，因为第一个 pod 请求了200 毫核，另一个请求了1000毫核，所以未使用的 CPU 将按照 1：5 的比例来划分给这两个 pod。如果两个 pod 都全力使用 CPU， 第一个 pod 将获得 16.7% 的 CPU 时间， 另一个将获得 83.3% 的 CPU 时间。</p>
<p>图14.2未使用的 CPU 时间按照 CPU requests 在容器之间分配<br>另一方面，如果一个容器能够跑满 CPU， 而另一个容器在该时段处于空闲状态， 那么前者将可以使用整个 CPU 时间（ 当然会减掉第二个容器消耗的少量时间）。毕竟当没有其他人使用时提高整个 CPU 的利用率也是有意义的，对吧？当然， 第二个容器需要 CPU 时间的时候就会获取到， 同时第一个容器会被限制回来。<br>14.1.4 定义和申请自定义资源<br>Kubernetes 允许用户为节点添加属于自己的自定义资源， 同时支持在 pod 资源requests里申请这种资源。 因为目前是一个 alpha 特性， 所以不打算描述其细节，而只会简短地介绍一下。<br>首先， 需要通过将自定义资源加入节点API 对象的 capacity 属性让Kubernetes 知道它的存在。 这可以通过执行HTTP的 PATCH 请求来完成。资源名</p>
<p>称可以是不以kubernetes.io 域名开头的任意值， 例如 example.org/my-resource，数量必须是整数 （例如不能设为 100m，因为 0.1 不是整数； 但是可以设置为1000m、2000m，或者简单地设为1 和2）。这个值将自动从 capacity字段 复制到 allocatable 字段。<br>然后，创建 pod 时，只要简单地在容器 spec 的 resources.requests 字段下， 或者像之前例子那样使用带—requests 参数的 kubectl run 命令来指定自定义资源名称和申请量， 调度器就可以确保这个 pod 只能部署到满足自定义资源申请量的节点，同时每个已部署的 pod 会减少节点的这类可分配资源数量。<br>一个自定义资源的例子就是节点上可用的 GPU 单元数量。如果 pod 需要使用 GPU，只要简单指定其 requests， 调度器就会保证这个 pod 只能调度到至少拥有一个未分配GPU单元的节点上。<br>14.2 限制容器的可用资源<br>设置 pod 的容器资源申请量保证了每个容器能够获得它所需要资源的最小量。现在我们再看看硬币的另一面一一容器可以消耗资源的最大量。<br>14.2.1 设置容器可使用资源量的硬限制<br>我们之前看到当其他进程处于空闲状态时容器可以被允许使用所有 CPU 资源。但是你可能想防止一些容器使用超过指定数量的 CPU， 而且经常会希望限制容器的可消耗内存数量。<br>CPU是一种可压缩资源，意味着我们可 以在不对容器内运行的进程产生不利影 响的同时，对其使用量进行限制。 而内存明显不同一是一种不可压缩资源。 一旦系统为进程分配了一块内存， 这块内存在进程主动释放之前将无法被回收。这就是我们为什么需要限制容器的最大内存分配量的根本原因。<br>如果不对内存进行限制，工作节点上的容器 （或者 pod）可能会吃掉所有可用 内存，会对该节点上所有其他 pod 和任何新调度上来的 pod（记住新调度的 pod 是基于内存的申请量而不是实际使用量的） 造成影响。单个故障 pod 或恶意 pod 几乎 可以导致整个节点不可用。<br>创建一个带有资源 limits 的 pod<br>为了防止这种情况发生，Kubernetes 允许用户为每个容器指定资源 limits（与设 置资源 requests 几乎相同）。 以下代码清单展示了一个包含资源 limits 的 pod 描述文件示例。</p>
<p>这个 pod 的容器包含了 CPU 和内存资源 limits 配置。容器内的进程不允许消耗 超过1核CPU和20MB内存。<br>注意：因为没有指定资源 requests， 它将被设置为与资源 limits 相同的值。<br>可超卖的 limits<br>与资源 requests 不同的是， 资源 limits 不受节点可分配资源量的约束。 所有 limits 的总和允许超过节点资源总量的 100% （见图 14.3）。换句话说，资源 limits 可 以超卖。如果节点资源使用量超过 100%， 一些容器将被杀掉，这是一个很重要的 结果。</p>
<p>图14.3节点上所有 pod 的资源 limits 之和可以超过节点资源总量的100%<br>在 14.3 节，我们将看到 Kubernetes如何决定杀掉哪些容器， 不过只要单个容器尝试使用比自己指定的 limits 更多的资源时也可能会被杀掉。 接下来我们会了解更多。</p>
<p>14.2.2 超过 limits<br>当容器内运行的进程尝试使用比限额更多的资源时会发生什么呢？<br>我们已经了解了 CPU 是可压缩资源， 当进程不等待 IO 操作时消耗所有的 CPU 时间是非常常见的。正如我们所知道的， 对一个进程的 CPU 使用率可以进行限制， 因此当为一个容器设置 CPU 限额时， 该进程只会分不到比限额更多的 CPU 而已。<br>而内存却有所不同。 当进程尝试申请分配比限额更多的内存时会被杀掉（我们会说这个容器被 OOMKilled 了，OOM 是 Out C Memory 的缩写）。如果 pod 的重 启策略为 Always 或 OnFailure， 进程将会立即重启，因此用户可能根本察觉不 到它被杀掉。但是如果它继续超限并被杀死， Kubernetes 会再次尝试重启，并开始 增加下次重启的间隔时间。 这种情况下用户会看到 pod 处于 CrashLoopBack0ff状态：<br>$ kubectl get po<br>NAME<br>READY<br>STATUS<br>RESTARTS<br>AGE<br>memoryhog 0/1<br>CrashLoopBack0ff<br>3<br>1m<br>CrashLoopBack0ff 状态表示 Kubelet还没有放弃， 它意味着在每次崩溃之后， Kubelet就会增加下次重启之前的间隔时间。 第一次崩溃之后，Kubelet 立即重启容器， 如果容器再次崩溃，Kubelet 会等待 10秒钟后再重启。随着不断崩溃， 延迟时间也会按照 20、40、80、160秒以几何倍数增长， 最终收敛在 300 秒。一旦间隔时间达 到300秒，Kubelet将以5 分钟为间隔时间对容器进行无限重启， 直到容器正常运行或被删除。<br>要定位容器 crash 的原因，可以通过查看 pod 日志以及 kubectl  describe pod命令：<br>代码清单 14.8<br>通过 kubectl describe pod 查看容器终止的原因 </p>
<p>oOMKilled状态告诉我们容器因为内存不足而被系统杀掉了。上例中，容器实际上已经超过了内存限额而被立即杀死。<br>让我们来讨论一下，当第-次开始为他们的容器指定限制时，大多数用户会被警惕。<br>因此，如果你不希望容器被杀掉，重要的一点就是不要将内存limits设置得很低。而容器有时即使没有超限也依然会被0OMKilled.我们将在14.3.2节说明原因，而现在让我们讨论一下在大多数用户首次指定limits时需要瞥惕的地方。<br>14.2.3容器中的应用如何看待limits<br>如果你还没有部署代码清单14.7 中的pod，请先部署：<br>$ kubectl create -f 1imi ted-pod. yaml<br>pod “1 imited-pod” created<br>现在我们在容器内运行top命令，如本章开始时那样。命令的输出显示在下面的代码清单中。<br>代码清单 14.9 在有CPUI 内存限制的容器内运行top命令</p>
<p>首先提醒一下，这个 pod 的 CPU 限额是 500 毫核，内存限额是20 MiB。现在 仔细审视一下 top 命令的输出。 看看有什么奇怪之处吗？<br>查看 used 和 free 内存量， 这些数值远超出我们为容器设置的20MiB 限额。同样地，我们设置了 CPU 限额为1 核， 即使我们使用的 dd 命令通常会消耗所有可用的 CPU 资源，但主进程似乎只用到了 50%。所以究竟发生了什么呢？<br>在容器内看到的始终是节点的内存， 而不是容器本身的内存<br>即使你为容器设置了最大可用内存的限额， top 命令显示的是运行该容器的节 点的内存数量，而容器无法感知到此限制。<br>这对任何通过查看系统剩余可用内存数量 ，并用这些信息来决定自己该使用多 </p>
<p>少内存的应用来说具有非常不利的影响。<br>对于Java程序来说这是个很大的问题，尤其是不使用-Xmx选项指定虚拟机的最大堆大小时，JVM会将其设置为主机总物理内存的百分值。在Kubernetes开发集群运行Java容器化应用（比如在笔记本电脑上运行）时，因为内存limits和笔记本电脑总内存差距不是很大，这个问题还不太明显。<br>但是如果pod部署在拥有更大物理内存的生产系统中，JVM将迅速超过预先配置的内存限额，然后被00M杀死。<br>也许你觉得可以简单地设置-Xmx选项就可以解决这个问题，那么你就错了，很遗憾。-Xmx选项仅仅限制了堆大小，并不管其他off-heap内存。好在新版本的Java会考虑到容器limits以缓解这个问题。<br>容器内同样可以看到节点所有的CPU核<br>与内存完全一样，无论有没有配置CPUlimits，容器内也会看到节点所有的CPU。将CPU限额配置为1，并不会神奇地只为容器暴露一个核。CPUlimits做的只是限制容器使用的CPU时间。<br>因此如果一个拥有1核CPU限额的容器运行在64核CPU上，只能获得1/64的全部CPU时间。而且即使限额设置为1核，容器进程也不会只运行在一个核上，不同时刻，代码还是会在多个核上执行。<br>上面的描述没什么问题，对吧？虽然一般情况下如此，但在一些情况下却是灾难。<br>一些程序通过查询系统CPU核数来决定启动工作线程的数量。同样在开发环境的笔记本电脑上运行良好，但是部署在拥有更多数量CPU的节点上，程序将快速启动大量线程，所有线程都会争夺（可能极其）有限的CPU时间。同时每个线程通常都需要额外的内存资源，导致应用的内存用量急剧增加。<br>不要依赖应用程序从系统获取的CPU数量，你可能需要使用Downward API将 CPU限额传递至容器并使用这个值。也可以通过cgroup系统直接获取配置的CPU 限制，请查看下面的文件：<br>●/sys/fs/cgroup/cpu/cpu.cfs_quota_us<br>●/sys/fs/cgroup/cpu/cpu.cfs_period_us<br>14.3了解podQoS等级<br>前面已经提到资源limits可以超卖，换句话说，一个节点不一定能提供所有pod所指定的资源limits之和那么多的资源量。<br>假设有两个pod，podA使用了节点内存的90%，podB突然需要比之前更多的</p>
<p>内存，这时节点无法提供足量内存，哪个容器将被杀掉呢？应该是podB吗？因为节点无法满足它的内存请求。或者应该是podA吗？这样释放的内存就可以提供给pod B了。<br>显然，这要分情况讨论。Kubernetes无法自己做出正确决策，因此就需要一种方式，我们通过这种方式可以指定哪种pod在该场景中优先级更高。Kubernetes将pod划分为3种QoS等级：<br>· BestEffort（优先级最低）<br>● Burstable<br>· Guaranteed（优先级最高）<br>14.3.1定义pod的QoS等级<br>你也许希望这个等级会通过一个独立的字段分配，但并非如此。QoS等级来源于pod所包含的容器的资源requests和limits的配置。下面介绍分配QoS等级的方法。为pod分配BestEffort等级<br>最低优先级的QoS等级是BestEffort。会分配给那些没有（为任何容器）设置任何requests和limits的pod。前面章节创建的pod都是这个等级。在这个等级运行的容器没有任何资源保证。在最坏情况下，它们分不到任何CPU时间，同时在需要为其他pod释放内存时，这些容器会第一批被杀死。不过因为BestEffort pod没有配置内存limits，当有充足的可用内存时，这些容器可以使用任意多的内存。 为pod分配Guaranteed等级<br>与Burstable相对的是Guaranteed等级，会分配给那些所有资源request和limits相等的pod。对于一个Guaranteed级别的pod，有以下几个条件：<br>·CPU和内存都要设置requests和limits<br>·每个容器都需要设置资源量<br>·它们必须相等（每个容器的每种资源的requests和limits必须相等）<br>因为如果容器的资源requests没有显式设置，默认与limits相同，所以只设置所有资源（pod内每个容器的每种资源）的限制量就可以使pod的QoS等级为Guaranteed。这些pod的容器可以使用它所申请的等额资源，但是无法消耗更多的资源（因为它们的limits和requests相等）。<br>为pod分配Burstable等级<br>Burstable QoS等级介于BestEffort和Guaranteed之间。其他所有的pod都属于这个等级。包括容器的requests和limits不相同的单容器pod，至少有一个容器只定义了requests但没有定义limits的pod，以及一个容器的request@</p>
<p>limits 相等，但是另一个容器不指定 requests 或 limits 的 pod。Burstable pod 可以获得它们所申请的等额资源， 并可以使用额外的资源（不超过 limits）。<br>requests 和 limits 之间的关系如何定义 QoS 等级<br>图 14.4 列举了3个QoS 等级和它们与 requests 和 limits 之间的关系。 </p>
<p>图14.4资源的requests、limits和QoS等级<br>考虑一个pod应该属于哪个QoS等级足以令人脑袋快速运转，因为它涉及多个容器、多种资源，以及requests和limits之间所有可能的关系。如果一开始从容器级别考虑QoS（尽管它并不是容器的属性，而是pod的属性），然后从容器QoS推导出podQoS，这样可能更容易理解。<br>明白容器的QOS等级<br>表14.1显示了基于资源requests和limits如何为单个容器定义QoS等级。对于单容器pod，容器的QoS等级也适用于pod。<br>表14.1基于资源请求量和限制量的单容器pod的QoS等级</p>
<p>注意如果设置了 requests而没有设置 limits， 参考表中requests 小于 limits 那一 行。如果设置了 limits，requests默认与 limits 相等，因此参考 request 等于 limits 那 </p>
<p>一行。<br>了解多容器pod的QoS等级<br>对于多容器pod，如果所有的容器的QoS等级相同，那么这个等级就是pod的 QoS等级。如果至少有一个容器的QoS等级与其他不同，无论这个容器是什么等级，这个pod的QoS等级都是Burstable等级。表14.2展示了pod的QoS等级与其中两个容器的QoS等级之间的对应关系。多容器pod可以对此进行简单扩展。<br>表14.2由容器的QoS等级推导出pod的QoS等级</p>
<p>注意运行 kubectl describe pod 以及通过 pod 的 YAML/JSON 描述的 status.qosClass字段都可以查看pod的 QoS等级。<br>我们解释了如何划分 QoS 等级， 但是我们依然需要 了解在一个超卖的系统中如何确定哪个容器先被杀掉。<br>14.3.2 内存不足时哪个进程会被杀死<br>在一个超卖的系统，QoS 等级决定着哪个容器第一个被杀掉， 这样释放出的资源可以提供给高优先级的 pod 使用。 BestEffort 等级的 pod 首先被杀掉， 其次是 Burstable pod，最后是 Guaranteed pod。Guaranteed pod 只有在系统进程  需要内存时才会被杀掉。<br>了解QoS 等级的优先顺序<br>请看图 14.5 中的例子。 假设两个单容器的 pod，第一个属于 BestEffort QoS等级，第二个属于 Burstable等级。 当节点的全部内存已经用完， 还有进程尝试申请更多的内存时， 系统必须杀死其中一个进程 （甚至包括尝试申请额外内存的进程）以兑现内存分配请求。 这种情况下，BestEffort 等级运行的进程会在Burstable 等级的进程之前被系统杀掉。</p>
<p>图14.5哪个pod 会第一个被杀掉<br>显然，BestEffort pod的进程会在Guaranteed pod的进程之前被杀掉。同样地，Burstable pod的进程也先于Guaranteed pod的进程被杀掉。但如果只有两个Burstable pod会发生什么呢？很明显需要选择~个优先于另一个的进程。如何处理相同QoS等级的容器<br>每个运行中的进程都有一个称为OutOfMemory（0OM）分数的值。系统通过比较所有运行进程的0OM分数来选择要杀掉的进程。当需要释放内存时，分数最高的进程将被杀死。<br>0OM分数由两个参数计算得出：进程已消耗内存占可用内存的百分比，与一个基于podQoS等级和容器内存申请量固定的0OM分数调节因子。对于两个属于Burstable等级的单容器的pod，系统会杀掉内存实际使用量占内存申请量比例更高的pod.这就是图14.5 中使用了内存申请量90%的pod B在podC （只使用了70%）之前被杀掉的原因，尽管podC比podB使用了更多兆字节的内存。<br>这说明我们不仅要注意requets和limits之间的关系，还要留心requests和预期实际消耗内存之间的关系。<br>14.4 为命名空间中的pod设置默认的requests和limits<br>我们已经了解到如何为单个容器设置资源requests和limits.如果我们不做限制，这个容器将处于其他所有设置了requests和limits的容器的控制之下。换句话说，为每个容器设置requests和limits是一个很好的实践。</p>
<p>14.4.1 LimitRange资源简介<br>用户可以通过创建一个LimitRange资源来避免必须配置每个容器。LimitRange资源不仅允许用户（为每个命名空间）指定能给容器配置的每种资源的最小和最大限额，还支持在没有显式指定资源requess时为容器设置默认值，如图14.6所示。</p>
<p>图 14.6 LimitRange用于 pod 的资源校验和设置默认值<br>LimitRange 资源被 LimitRanger准入控制插件（我们在第 11 章介绍过这种插件）。 API 服务器接收到带有 pod 描述信息的 POST 请求时，LimitRanger插件对 pod spec 进行校验。如果校验失败，将直接拒绝。 因此，LimitRange 对象的一个广泛应用场 景就是阻止用户创建大于单个节点资源量的 pod。如果没有 LimitRange，API服务 器将欣然接收 pod 创建请求， 但永远无法调度成功。<br>LimitRange 资源中的 limit 应用于同一个命名空间中每个独立的pod、 容器，或者其他类型的对象。 它并不会限制这个命名空间中所有 pod 可用资源的总量，总量是通过 ResourceQuota 对象指定的， 这将在 14.5 节中进行说明。<br>14.4.2 LimitRange 对象的创建<br>我们看一下 LimitRange 的全貌， 然后单独解释每个属性的作用。下面的代码 </p>
<p>单展示了一个 Limit Range资源的完整定义。<br>代码清单14.10LimitRange资源:limits.yaml</p>
<p>正如在，上面例子中看到的，整个pod资源限制的最小值和最大值是可以配置的。它应用于pod内所有容器的requests和limits之和。<br>在更低一层的容器级别，用户不仅可以设置最小值和最大值，还可以为没有显式指定的容器设置资源request s（de faultRequest）和limit s（default）的默认值。<br>除了最小值、最大值和默认值，用户甚至可以设置limits和requests最大比例。.上面示例中设置了maxLimi tRequestRatio为4，表示容器的CPU limits不能超过CPU requests的4倍。因此，对于一个申请了200毫核的容器，如果它的CPU限额设置为801毫核或者更大就无法创建。而对于内存，这个比例设为了10。<br>在第6章我们介绍了PersistentVolumeClaim （PVC），正如在pod中为容器声明</p>
<p>CPU和内存一样， 用户也可以声明指定大小的持久化存储。<br>这个例子只使用一个 LimitRange 对象， 其中包含了对所有资源的限制，而如果 你希望按照类型进行组织， 也可以将其分割为多个对象 （例如一个用于 pod 限制，一个用于容器限制，一个用于 PVC 限制）。 多个 LimitRange 对象的限制会在校验 pod 或 PVC 合法性时进行合并。<br>由于LimitRange 对象中配置的校验 （和默认值）信息在API 服务器接收到新的pod 或 PVC 创建请求时执行， 如果之后修改了限制， 已经存在的 pod和 PVC 将不会再次进行校验， 新的限制只会应用于之后创建的 pod 和 PVC。<br>14.4.3<br>强制进行限制<br>在设置了限制的情况下，我们尝试创建一个 CPU 申请量大于 LimitRange 允许 值的 pod。可以在代码库中找到 pod 的 YAML。下面的代码清单仅展示与本节讨论 相关的部分。<br>代码清单 14.11一个 CPU requests超过限制的 pod： limits-pod-too-big.yaml resources:<br>requests:<br>cpu: 2<br>这个 pod 的容器需要2 核 CPU， 大于之前 LimitRange 中设置的最大值。 创建pod 时会返回以下结果：<br>$ kubectl create -f limits-pod-too-big.yaml<br>Error from server (Forbidden): error when creating ‘limits-pod-too-big.yaml”: pods “too-big” is forbidden: [<br>maximum cpu usage per Pod is 1, but request is 2.,<br>maximum cpu usage per Container is 1, but request is 2.]<br>为了看起来更清晰， 笔者对输出结果稍微做了修改。 服务器返回错误信息的好处是它列出了这个 pod 被拒绝的所有原因， 而不仅仅是第一个错误。正如我们从结 果看到的，pod 被拒绝的原因有两个： 我们为容器申请了2核的 CPU，但是容器的 最大 CPU 请求量限制为1核， 在 Pod 级别也是同样的原因， pod 整体可以请求2核的 CPU，但是允许申请的最大值是1核 （如果这是一个多容器 pod，即使每个单独 容器的请求量少于最大 CPU 请求量， 所有容器请求量的总和仍然需要少于2 核才能符合最大 CPU 请求量的限制）。<br>14.4 应用资源 requests 和 limits 的默认值<br>现在我们再看看如果不指定资源 requests 和 limits，Kubernetes 如何为其设置中 </p>
<p>认值，我们再次部署第3章中名叫kubia-manual的pod ：<br>$ kubectl. ereate. 一E ../chaptex03/kubia manual.yaml<br>$ kubectl create<br>/Chapt<br>pod “kubia-manual” created<br>在我们设置LimitRange对象之前，所有pod创建后都不包含资源requests或limits，但现在我们通过describe确认一下刚刚创建的kubia-manual pod ：<br>代码清单14.12检查 自动应用于pod的limits<br>$ kubectl describe po kubia-manual<br>Name:<br>ubinmanual<br>vatle i<br>KuD1a -manual<br>oont.<br>Containers: kubia:<br>Limits:<br>cou: memors<br>20Om<br>memory: 100Mi<br>Requests:<br>cpu: 100m<br>memory: 1 OMi<br>容器的requests和limits与我们在LimitRange对象中设置的-致。如果我们在另一个命名空间中指定不同的LimitRange，那么这个命名空间中创建的pod就会拥有不同的requests和limits.这样管理员就可以为每个命名空间的pod配置资源的默认值、最小值和最大值。如果使用命名空间来区分不同团队，或是区分开发、测试、交付准备，以及生产环境的pod都运行在相同的Kubernetes集群中，那么在每个命名空间中定义不同的LimitRange就可以确保只在特定的命名空间中可以创建资源需求大的pod，而在另一些命名空间中只能创建资源需求小的pod.<br>但需要记住的是，LimitRange中配置的limits只能应用于单独的pod或容器。用户仍然可以创建大量的pod吃掉集群所有可用资源。LimitRange并不能防止这个问题，而相反，我们将在下文了解的ResourceQuota对象可以做到这点。<br>14.5限制命名空间中的可用 资源总量<br>正如我们看到的，LimitRange只应用于单独的pod，而我们同时也需要一种手段可以限制命名空间中的可用资源总量。这通过创建—个ResourceQuota对象来实现。 14.5.1 ResourceQuota资源介绍<br>在第10章中我们讨论了几种运行在API服务器中，可以判断一个pod是否允许创建的接纳控制插件。在上一节，我们讲到LimitRanger插件会强制执行</p>
<p>LimitRange 资源中配置的策略。类似地， ResourceQuota 的接纳控制插件会检查将要 创建的 pod 是否会引起总资源量超出 ResourceQuota。如果那样， 创建请求会被拒绝。因为资源配额在 pod 创建时进行检查， 所以 ResourceQuota 对象仅仅作用于在其后 创建的pod-一并不影响已经存在的 pod。<br>资源配额限制了一个命名空间中 pod 和 PVC 存储最多可以使用的资源总量。同 时也可以限制用户允许在该命名空间中创建 pod、PVC， 以及其他 API 对象的数量，因为到目前为止我们处理最多的资源是 CPU 和内存，下面就来看看如何为这两种资源指定配额。<br>为 CPU和内存创建 ResourceQuota<br>限制命名空间中所有 pod 允许使用的 CPU 和内存总量可以通过创建 ResourceQuota 对象来实现， 请看下面的代码清单。<br>代码清单 14.13memory.yaml<br>CPU 和内存的 ResourceQuota 资源： memory： quota-cpu- </p>
<p>我们为 CPU 和内存分别定义了 requests 和 limits 总量，而不是简单地为每种资 源只定义一个总量。你可能会注意到与 LimitRange 对比，结构有一些不同。 这里所有资源的 requests 和 limits 都定义在一个字段下。<br>这个 ResourceQuota 设置 了命名空间中所有 pod 最多可申请的 CPU数量为 400 毫核，limits 最大总量为600毫核。 对于内存，设置所有 requests 最大总量为  200MiB，limits为500MiB。<br>与LimitRange一样，ResourceQuota 对象应用于它所创建的那个命名空间，但 不同的是，后者可以限制所有 pod 资源 requests 和 limits 的总量，而不是每个单独 的 pod 或者容器，如图 14.7 所示。</p>
<p>图14.7LimitRange 应用于单独的 pod； ResourceQuota 应用于命名空间中所有的 pod<br>查看配额和配额使用情况<br>将 ResourceQuota 对象提交至 API 服务器之后，可以执行 kubectl describe命令查看当前配额已经使用了多少， 如以下代码清单所示。<br>代码清单 14.14 使用kubectl describe quota 查看配额<br>$ kubectl degcribe quota Name:<br>cpu-and-mem<br>Namespace:<br>default<br>Resource<br>Used<br>Hard<br>limits.cpu<br>200m<br>600m<br>limits.memory<br>100Mi<br>500Mi<br>requests.cpu<br>100m<br>400m<br>requests.memory 10Mi<br>200Mi<br>因为我们只运行了 kubia-manual pod， 所以 Used 列与这个 pod 的 requests 和 limits 相等。如果我们再运行其他 pod， 它们的 requests 和 limits 值会增加至已使 用量中。<br>与ResourceQuota 同时创建 LimitRange<br>需要注意的一点是，创建 ResourceQuota 时往往还需要随之创建一个 LimitRange 对象。在上一节我们已经配置了 LimitRange，但是假设我们没有配置，  kubia-manual pod 将无法成功创建， 因为它没有指定任何资源  requests和 limits。 我们看一下这种情况会发生什么：<br>$ kubectl create -f . /Chapter03/kubia-manual.yaml<br>Error from server (Forbidden): error when creating”. /Chapter03/kubia-<br>manual.yaml”: pods “kubia-manual” is forbidden: failed quota: cpu-and- mem: must specify limits.cpu,limits.memory,requests.cpu,requests..memory<br>因此，当特定资源（CPU 或内存）配置了 （requests 或 limits）配额，在 pod 中 </p>
<p>必须为这些资源（分别）指定requests或limits，否则API服务器不会接收该pod的创建请求。<br>14.5.2为持久化存储指定配额<br>ResourceQuota对象同样可以限制某个命名空间中最多可以声明的持久化存储总量，如以下代码清单所示。<br>代码清单14.15为存储配置ResourceQuota： quota-storage.yaml<br>apiVersion:vl<br>kind:ResourceQuota<br>可声明存<br>metadata:<br>储总量<br>name: storage<br>spec:<br>hard:<br>StorageClass<br>requests.storage: 500Gi<br>&lt;<br>ssd的可申请的<br>ssd.storageclass.storage.k8s.io/requests.storage: 300Gi&lt;<br>存储量<br>standard.storageclass.storage.k8s.io/requests.storage: 1Ti<br>在这个例子中，Namespace中所有可申请的PVC总量被限制为500GiB（通过配额对象中的requests.storage）。如果你记得第6章，PVC可以申请一个特定StorageClass、动态提供的PV（PersistentVolume）。这就是为什么Kubernetes同样允许单独为每个StorageClass提供定义存储配额的原因。上面的示例限制了可声明的SSD存储（以ssd命名的StorageClass）的总量为300GiB。低性能的HDD存储（StorageClass standrad）限制为1TiB。<br>14.5.3限制可创建对象的个数<br>资源配额同样可以限制单个命名空间中的pod、ReplicationController. Service以及其他对象的个数。集群管理员可以根据比如付费计划限制用户能够创建的对象个数，同时也可以用来限制公网IP或者Service可使用的节点端口个数。<br>下面的代码清单展示了一个限制对象个数的ResourceQuota定义：<br>代码清单14.16一个限制了资源最大个数的ResourceQuota ： quota-object-count.yam</p>
<p>上面的例子允许用户在一个命名空间中最多创建 10 个 pod，无论是手动创建还 是通过 ReplicationController、ReplicaSet、 DaemonSet 或者 Job 创建的。同时限制了  ReplicationController 最大个数为 5，Service 最大个数为 5，其中 LoadBalancer 类型 最多 1 个，NotPort类型最多 2 个。 与通过指定每个 StorageClass 来限制存储资源的申请总量类似，PVC 的个数同样可以按照 StorageClass来限制。<br>对象个数配额目前可以为以下对象配置：<br>●pod<br>ReplicationController<br>Secret<br>ConfigMap<br>Persistent Volume Claim<br>Service（通用）， 以及两种特定类型的 Service， 比如 LoadBalancer Service（services.loadbalancers） 和 NodePort Service（services.  nodeports)<br>最后，甚至可以为 ResourceQuota对象本身设置对象个数配额。 其他对象的个数，比如 ReplicaSet、Job、Deployment、 Ingress 等暂时不能限制 （不过在本书出版后可能有所改变， 因此请参考最新文档获取更多信息）。<br>14.5.4 为特定的 pod 状态或者 QoS 等级指定配额<br>目前为止我们创建的 Quota 应用于所有的 pod，不管 pod 的当前状态和QoS等级如何。但是Quota 可以被一组 quota scopes 限制。目前配额作用范围共有 4 种： BestEffort、NotBestEffort、 Termination 和 NotTerminating.<br>BestEffort和NotBestEffort 范围决定配额是否应用于 BestEffort QoS 等级或者其他两种等级（Burstable 和Guaranteed）的 pod。 </p>
<p>其他两个范围（Terminating和NotTerminating）的名称或许有些误导作用，实际上并不应用于处在（或不处在）停止过程中的pod。我们尚未讨论过这个问题，但你可以为每个pod指定被标记为Failed，然后真正停止之前还可以运行多长时间。这是通过在pod spec中配置activeDeadlineSeconds来实现的。该属性定义了一个pod从开始尝试停止的时间到其被标记为Failed然后真正停止之前，允许其在节点上继续运行的秒数。Terminating配额作用范围应用于这些配置了activeDeadlineSeconds的pod，而NotTerminating应用于那些没有指定该配置的pod。<br>创建ResourceQuota时，可以为其指定作用范围。目标pod必须与配额中配置的所有范围相匹配。另外，配额的范围也决定着配额可以限制的内容。BestEffort范围只允许限制pod个数，而其他了种范围除了pod个数，还可以限制CPU/内存的requests和limits。<br>例如，如果只想将配额应用于BestEffort、NotTerminating的pod，可以创建如以下代码清单所示的ResourceQuota对象。<br>代码列表14.17为BestEffort/NotTerminating pod设置ResourceQuota : quota-scoped.yam</p>
<p>这个配额允许最多创建4个属于BestEffortQoS等级，并没有设置activedeadline 的pod。如果配额针对的是NotBestEffort pod，我们便可以指定requests.cpu，requests.memory，limits.cpu和limits.memory。<br>注意在进入到下一个部分之前，请删除创建的所有的ResourceQuota和LimitRange资源。接下来不会用到这些资源，而且这些资源会干扰接下来的例子。<br>14.6 监控pod的资源使用量<br>设置合适的资源requests和limits对充分利用Kubernetes集群资源来说十分重</p>
<p>要。如果requests设置得太高，集群节点利用率就会比较低，这样就白白浪费了金钱。如果设置得太低，应用就会处于CPU饥饿状态，甚至很容易被00MKiller杀死。所以如何才能找到requests和limits的最佳配置呢？<br>可以通过对容器在期望负载下的资源实际使用率进行监控来找到这个最佳配置。当然一旦应用暴露于公网，都应该保持监控并且在需要时对其资源的requests和limits进行调节。<br>14.6.1收集、获取实际资源使用情况<br>那么如何监控一个在Kubernetes中运行的应用呢？幸运的是，Kubelet自身就包含了一个名为cAdvisor的agent，它会收集整个节点和节点上运行的所有单独容器的资源消耗情况。集中统计整个集群的监控信息需要运行一个叫作Heapster的附加组件。<br>Heapster 以pod的方式运行在某个节点上，它通过普通的Kubernetes Service暴露服务，使外部可以通过一个稳定的IP地址访问。它从集群中所有的cAdvisor 收集数据，然后通过一个单独的地址暴露。图14.8展示了来源于pod的监控指标数据，经过cAdvisor最终到达Heapster的数据流。</p>
<p>图14.8进入 Heapster的监控指标数据流<br>图中的箭头表示监控数据流动的方向，它并不代表组件之间用来获取数据的连接关系。pod （或者pod中运行的容器）感知不到cAdvisor的存在，cAdvisor 也感知不到Heapster的存在。Heapster 主动请求所有的cAdvisor，同时cAdvisor无须通过与pod容器内进程通信就可以收集到容器和节点的资源使用数据。</p>
<p>启用Heapster<br>如果你的集群运行在Google Container Engine. 上，Heapster 默认已经启用。如果你使用的是Minikube，它可以作为插件使用，通过以下命令开启：<br>$ minikube addons enable heaps ster<br>heapster was successfully enabled<br>如果要在其他类型的Kubemetes集群中手动运行Heapster，可以参考<a href="https://github" target="_blank" rel="noopener">https://github</a>. com/kubemetes/heapster中的介绍。<br>启用了Heapster之后，可能需要等待几分钟时间收集足够的指标，才能看到集群资源的使用统计，因此耐心地等待一会 儿吧。<br>显示集群节点的CPU和内存使用量<br>在集群中运行Heapster可以通过kubectl to p命令获得节点和单个pod的资源用量。要看节点使用了多少CPU和内存，可以执行以下代码清单所示的命令。<br>代码清单14.18节 点实际CPU和内存使用量<br>$ kubectl top node<br>CDTIOOrec NAME..<br>cpu<br>CPU （cores） CPU号<br>MEMORY (bytes ) MEMORY%<br>minikube 170m 8号556Mi<br>27号<br>它显示了节点上运行的所有pod当前的CPU和内存的实际使用量，与kubec tl desc ribe no de命令不同的是，后者仅仅显示节点CPU和内存的requests和limits，而不是实际运行时的使用数据。<br>显示单独pod的CPU和内存使用量<br>要查看每个pod使用了多少资源，可以使用kubec tl to p po d令，如以下代码清单所示。<br>代码清单14.19 pod CPU和内存的实际使用量<br>$ kubectl top pod —a11-naneapaces<br>NAMESPACE NAME<br>CPU(cores) MEMORY (bytes)<br>kube - system kube- svstem defauit aetault_ kube-system kube-system kube- system<br>influxdb-grafana- 2r2w9<br>32Mi 1an: 9Mi 11M1 14Mi 22Ni<br>heapster-40i6d<br>m<br>kubia- 377318213 - 63bmb<br>kubia-<br>kube-dns-v20-z0hq6<br>kubernetes-dashboard-r53mc<br>kube-addon- manager-mini kube<br>这两个命令的输出都相当简单，因此也许不需要过多解释，然而有一点需要提醒的是，有时toppod命令矩绝输出任何指标而输出以下错误：</p>
<p>如果看到这个错误， 先不要急于寻找出错的原因，放松一下，然后等待一会儿重新执行可能需要好几分钟，不过最终会看到指标的。因为kubectl top 命令从Heapster中获取指标，它将几分钟的数据汇总起来，所以通常不会立即暴露。<br>提示要查看容器而不是pod的资源使用情况，可以使用—container选项。14.6.2保存并 分析历史资源的使用统计信息<br>top 命令仅仅展示了当前的资源使用量一它 并不会显示比如从一小时、一天或者一周前到现在pod的CPU和内存使用了多少。事实上，cAdvisor 和Heapster都只保存一个很短时间窗的资源使用量数据。如果需要分析一段时间的pod的资源使用情况，必须使用额外的工具。如果使用Google Container Engine， 可以通过Google Cloud Monitoring来对集群进行监控，但是如果是本地Kubemetes集群（通过Minikube或其他方式创建），人们往往使用InfuxDB来存储统计数据，然后使用Grafana对数据进行可视化和分析。<br>InfluxDB和Grafana介绍<br>InfuxDB是一个用于存储应用指标，以及其他监控数据的开源的时序数据库。 Grafana是一个拥有着华丽的web控制台的数据分析和可视化套件，同样也是开源的，它允许用户对InfuxDB中存储的数据进行可视化，同时发现应用程序的资源使用行为是如何随时间变化的（图14.9展示了3个Grafana图表示例）。<br>在集群中运行InfluxDB和Grafana<br>InfuxDB和Grafana都可以以pod运行，部署简单方便。所有需要的部署文件可以在HeapsterGit仓库中获取:<a href="http://github.com/kubemetes/heapster/tree/master/deploy/kube-" target="_blank" rel="noopener">http://github.com/kubemetes/heapster/tree/master/deploy/kube-</a> config/infuxdb.<br>如果使用Minikube就无须手动部署，因为启用Heapster插件时便会随之部署Heapster.</p>
<p>图14.9展示集群级别 CPU 使用量的 Grafana 面板<br>使用Grafana 分析资源使用量<br>要发现 pod 对每种资源的需求是如何随时间变化的， 打开Grafana web 控制台，开始浏览一些预先定义的面板。 通常可以通过 kubectl cluster-info 命令找到Grafana web 控制台的 URL。<br>$ kubectl cluster-info<br>monitoring-grafana is running at<br><a href="https://192.168.99.1008443/api/v1/proxy/namespaces/kube-" target="_blank" rel="noopener">https://192.168.99.1008443/api/v1/proxy/namespaces/kube-</a><br>system/services/monitoring—grafana<br>使用 minikube 时，Grafana的 web 控制台通过 NodePort Service暴露，因此我们使用以下命令在浏览器中将其打开：<br>$ minikube service monitoring-grafana -n kube-system<br>Opening kubernetes service kube-system/monitoring-grafana in default<br>browser…<br>这将打开一个新的浏览器窗口或标签页， 显示 Grafana 的主页面。在右边可以 看到一个包含两个入口的面板列表：</p>
<p>Cluster<br>pod<br>打开Cluster 面板， 可以看到节点的资源使用统计。 在这里你将看到一些展示着集群整体使用量、单节点使用量，以及 CPU、内存、网络和文件系统单独使用量 的图表。 这些图表不仅展示了资源的实际使用量， 也展示了这些资源的 requests 和limits。<br>接着如果你切换到 pod 面板， 你将看到每个单独 pod 的资源使用情况， requests和 limits 与实际使用量也在一起展示。 图表默认展示最近30分钟的统计数据， 不过你可以通过缩小以看到更长时间段一 比如几天、几个月甚至几年的数据。<br>利用图表中展示的信息<br>通过查看图表， 你将快速看到是否需要提高之前为 pod 设置的资源 requests 或limits值， 或者是否需要降低配置以允许更多的 pod 可以调度到节点上。我们来看一个示例，图 14.10 展示了一个 pod 的 CPU 和内存图表。 </p>
<p>在顶部图表的最右侧，可以看到pod实际CPU使用量要比pod定义中指定的申请量更多。尽管如果节点上只运行这一个pod时没有什么问题，但需要注意的是，pod只能保证获取到与其请求量相等的资源。这个pod也许现在运行良好，但是当其他pod部署在相同节点并开始大量使用CPU时，这个pod的CPU时间将被限制。因此，为了保证这个pod可以在任何时候都能使用足够的CPU，需要提升容器的CPU资源请求量。<br>图表的底部显示了pod的内存使用量和请求量。这个情况恰恰相反，pod使用的内存数量远远低于pod spec中的请求量。这部分内存会始终为这个pod保留而且对其他pod来说也不能使用。因此这些未使用的内存被浪费了。我们应该降低pod的内存请求量，使其他pod可以使用这个节点上空闲的内存。<br>14.7<br>本章小结<br>本章讲述了为了确保一切顺利运行，你需要考虑pod的资源使用情况，同时为pod同时配置资源requests和limits。本章的主要内容是<br>·指定资源requests，帮助Kubernetes在集群内对pod进行调度<br>·指定资源limits，防止一个pod抢占其他pod的资源<br>空闲的CPU时间根据容器的CPUrequests来分配<br>·如果容器使用过量的CPU，系统不会杀死这个容器，但如果使用过量的内存会被杀死<br>·在一个overcommited的系统，容器同样可以被杀死以释放内存给更重要的pod，这基于pod的QoS等级和实际内存用量<br>，可以通过LimtRange对象为单个pod的资源requests和limits定义最小值、 最大值和默认值<br>可以通过ResourceQuota对象限制一个命名空间中所有pod的可用资源数量。要知道如何为pod设置合适的资源requests和limits，需要对一段足够长时间内pod资源的使用情况进行监控<br>在下一章，我们将了解Kubernetes如何使用这些指标对pod进行自动扩缩容。</p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Kubernetes-in-Action/" rel="tag"># Kubernetes in Action</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2022/10/01/13-保障集群内节点和网络安全/" rel="next" title="13-保障集群内节点和网络安全">
                <i class="fa fa-chevron-left"></i> 13-保障集群内节点和网络安全
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2022/10/01/15-自动横向伸缩pod与集群节点/" rel="prev" title="15-自动横向伸缩pod与集群节点">
                15-自动横向伸缩pod与集群节点 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="CheBin">
            
              <p class="site-author-name" itemprop="name">CheBin</p>
              <div class="site-description motion-element" itemprop="description">看书不是为了学习，是为了锻炼意志力</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">896</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">19</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">63</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          


          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <!-- modify icon to fire by szw -->
                <i class="fa fa-history fa-" aria-hidden="true"></i>
                近期文章
              </div>
              <ul class="links-of-blogroll-list">
                
                
                  <li>
                    <a href="/2023/01/27/47｜故障容错：如何在Worker崩溃时进行重新调度？/" title="47｜故障容错：如何在Worker崩溃时进行重新调度？" target="_blank">47｜故障容错：如何在Worker崩溃时进行重新调度？</a>
                  </li>
                
                  <li>
                    <a href="/2023/01/27/46｜Master任务调度：服务发现与资源管理/" title="46｜Master任务调度：服务发现与资源管理" target="_blank">46｜Master任务调度：服务发现与资源管理</a>
                  </li>
                
                  <li>
                    <a href="/2023/01/27/45｜Master高可用：怎样借助etcd实现服务选主？/" title="45｜Master高可用：怎样借助etcd实现服务选主？" target="_blank">45｜Master高可用：怎样借助etcd实现服务选主？</a>
                  </li>
                
                  <li>
                    <a href="/2023/01/27/44｜一个程序多种功能：构建子命令与flags/" title="44｜一个程序多种功能：构建子命令与flags" target="_blank">44｜一个程序多种功能：构建子命令与flags</a>
                  </li>
                
                  <li>
                    <a href="/2023/01/27/43｜分布式协调：etcd读写、MVCC原理与监听机制/" title="43｜分布式协调：etcd读写、MVCC原理与监听机制" target="_blank">43｜分布式协调：etcd读写、MVCC原理与监听机制</a>
                  </li>
                
              </ul>
            </div>
        

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 – <span itemprop="copyrightYear">2023</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CheBin</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">站点总字数：</span>
    
    <span title="站点总字数">7.6m</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    
    <span title="站点阅读时长">115:03</span>
  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a></div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.1"></script>

  <script src="/js/src/motion.js?v=7.0.1"></script>



  
  


  <script src="/js/src/affix.js?v=7.0.1"></script>

  <script src="/js/src/schemes/pisces.js?v=7.0.1"></script>



  
  <script src="/js/src/scrollspy.js?v=7.0.1"></script>
<script src="/js/src/post-details.js?v=7.0.1"></script>



  


  <script src="/js/src/next-boot.js?v=7.0.1"></script>


  

  

  

  


  


  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  

  
  

  


  

  

  

  

  

  

  

  

  
<script>
  $('.highlight').each(function(i, e) {
    var $wrap = $('<div>').addClass('highlight-wrap');
    $(e).after($wrap);
    $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function(e) {
      var code = $(this).parent().find('.code').find('.line').map(function(i, e) {
        return $(e).text();
      }).toArray().join('\n');
      var ta = document.createElement('textarea');
      var yPosition = window.pageYOffset || document.documentElement.scrollTop;
      ta.style.top = yPosition + 'px'; // Prevent page scroll
      ta.style.position = 'absolute';
      ta.style.opacity = '0';
      ta.readOnly = true;
      ta.value = code;
      document.body.appendChild(ta);
      ta.select();
      ta.setSelectionRange(0, code.length);
      ta.readOnly = false;
      var result = document.execCommand('copy');
      
        if (result) $(this).text('复制成功');
        else $(this).text('复制失败');
      
      ta.blur(); // For iOS
      $(this).blur();
    })).on('mouseleave', function(e) {
      var $b = $(this).find('.copy-btn');
      setTimeout(function() {
        $b.text('复制');
      }, 300);
    }).append(e);
  })
</script>


  

  

</body>
</html>
